{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b575a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "import openpyxl\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83eb5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7486878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_false(df, group):\n",
    "    \"\"\"\n",
    "    计算每个组别在不同孕周t的条件false比例\n",
    "    P_false(t) = (截至t周的 y染色体浓度<0.04 样本数) / (截至t周的总样本数)\n",
    "    \"\"\"\n",
    "    group_data = df[df['组别'] == int(group)].copy()\n",
    "    group_data = group_data.sort_values('week')  \n",
    "    \n",
    "    t_values = np.arange(70, 28*7, 7)\n",
    "    results = {}\n",
    "    \n",
    "    for t in t_values:\n",
    "        # 截至t周的所有样本\n",
    "        samples_up_to_t = group_data[group_data['week'] <= t]\n",
    "        total_up_to_t = len(samples_up_to_t)\n",
    "        \n",
    "        if total_up_to_t == 0:\n",
    "            results[t] = 1  # 如果没有样本，设为1,相当于排除掉这个t\n",
    "        else:\n",
    "            # 截至t周的false样本（Y<0.04）\n",
    "            false_t = len(samples_up_to_t[samples_up_to_t['Y染色体浓度'] < 0.04])\n",
    "            results[t] = false_t / total_up_to_t  \n",
    "\n",
    "            results[t] = np.where(results[t]>0.1, results[t], 0.1) # 样本数过少时，拟合的结果相当于增加了隐性风险\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f760ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_late(t):\n",
    "    if t <= 12*7: \n",
    "        return 0\n",
    "    elif t > 12*7 and t < 7*28:\n",
    "        return (t - 12*7) / (7*(28 - 12))\n",
    "    else:\n",
    "        return 1 # 28之后已经有很高风险，直接增加大的惩罚\n",
    "# 我们认为，在早期之后，随着时间增加风险线性增加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d6db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(P_false_curves, w1=0.7, w2=0.3):\n",
    "    \"\"\"\n",
    "    计算每个组别的风险函数并找出最优检测时间\n",
    "    Risk(t) = w1 * P_false(t) + w2 * P_late(t)\n",
    "    \"\"\"\n",
    "    risk_results = {}\n",
    "    optimal_times = {}\n",
    "    \n",
    "    for group, p_false_curve in P_false_curves.items():\n",
    "        group_risk = {}\n",
    "        \n",
    "        # 计算每个t的风险值\n",
    "        for t, p_false in p_false_curve.items():\n",
    "            risk = w1 * p_false + w2 * P_late(t)\n",
    "            group_risk[t] = risk\n",
    "        \n",
    "        # 找到风险最小的t\n",
    "        min_risk_t = min(group_risk.items(), key=lambda x: x[1])[0]\n",
    "        min_risk_value = group_risk[min_risk_t]\n",
    "        \n",
    "        risk_results[group] = group_risk\n",
    "        optimal_times[group] = (min_risk_t, min_risk_value)\n",
    "    \n",
    "    return risk_results, optimal_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27af7df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.int64(2): {np.int64(70): 1,\n",
       "  np.int64(77): array(0.1),\n",
       "  np.int64(84): array(0.16216216),\n",
       "  np.int64(91): array(0.13265306),\n",
       "  np.int64(98): array(0.11971831),\n",
       "  np.int64(105): array(0.10714286),\n",
       "  np.int64(112): array(0.11538462),\n",
       "  np.int64(119): array(0.132),\n",
       "  np.int64(126): array(0.12790698),\n",
       "  np.int64(133): array(0.13207547),\n",
       "  np.int64(140): array(0.13103448),\n",
       "  np.int64(147): array(0.12944984),\n",
       "  np.int64(154): array(0.12658228),\n",
       "  np.int64(161): array(0.12578616),\n",
       "  np.int64(168): array(0.11904762),\n",
       "  np.int64(175): array(0.11396011),\n",
       "  np.int64(182): array(0.11267606),\n",
       "  np.int64(189): array(0.11204482)},\n",
       " np.int64(3): {np.int64(70): array(0.1),\n",
       "  np.int64(77): array(0.1),\n",
       "  np.int64(84): array(0.11764706),\n",
       "  np.int64(91): array(0.15929204),\n",
       "  np.int64(98): array(0.11675127),\n",
       "  np.int64(105): array(0.1),\n",
       "  np.int64(112): array(0.1),\n",
       "  np.int64(119): array(0.11082474),\n",
       "  np.int64(126): array(0.1092233),\n",
       "  np.int64(133): array(0.10926366),\n",
       "  np.int64(140): array(0.11111111),\n",
       "  np.int64(147): array(0.11740891),\n",
       "  np.int64(154): array(0.11729622),\n",
       "  np.int64(161): array(0.12062257),\n",
       "  np.int64(168): array(0.11403509),\n",
       "  np.int64(175): array(0.11148649),\n",
       "  np.int64(182): array(0.11148649),\n",
       "  np.int64(189): array(0.11129848)},\n",
       " np.int64(4): {np.int64(70): 1,\n",
       "  np.int64(77): 1,\n",
       "  np.int64(84): array(0.25),\n",
       "  np.int64(91): array(0.42857143),\n",
       "  np.int64(98): array(0.42857143),\n",
       "  np.int64(105): array(0.375),\n",
       "  np.int64(112): array(0.34375),\n",
       "  np.int64(119): array(0.34090909),\n",
       "  np.int64(126): array(0.34693878),\n",
       "  np.int64(133): array(0.33333333),\n",
       "  np.int64(140): array(0.33898305),\n",
       "  np.int64(147): array(0.33783784),\n",
       "  np.int64(154): array(0.33766234),\n",
       "  np.int64(161): array(0.33333333),\n",
       "  np.int64(168): array(0.29166667),\n",
       "  np.int64(175): array(0.29357798),\n",
       "  np.int64(182): array(0.28828829),\n",
       "  np.int64(189): array(0.28571429)},\n",
       " np.int64(5): {np.int64(70): 1,\n",
       "  np.int64(77): 1,\n",
       "  np.int64(84): 1,\n",
       "  np.int64(91): array(1.),\n",
       "  np.int64(98): array(1.),\n",
       "  np.int64(105): array(1.),\n",
       "  np.int64(112): array(1.),\n",
       "  np.int64(119): array(0.8),\n",
       "  np.int64(126): array(0.8),\n",
       "  np.int64(133): array(0.8),\n",
       "  np.int64(140): array(0.71428571),\n",
       "  np.int64(147): array(0.625),\n",
       "  np.int64(154): array(0.55555556),\n",
       "  np.int64(161): array(0.55555556),\n",
       "  np.int64(168): array(0.41666667),\n",
       "  np.int64(175): array(0.38461538),\n",
       "  np.int64(182): array(0.38461538),\n",
       "  np.int64(189): array(0.38461538)},\n",
       " np.int64(1): {np.int64(70): 1,\n",
       "  np.int64(77): 1,\n",
       "  np.int64(84): 1,\n",
       "  np.int64(91): 1,\n",
       "  np.int64(98): array(1.),\n",
       "  np.int64(105): array(1.),\n",
       "  np.int64(112): array(1.),\n",
       "  np.int64(119): array(0.5),\n",
       "  np.int64(126): array(0.5),\n",
       "  np.int64(133): array(0.5),\n",
       "  np.int64(140): array(0.66666667),\n",
       "  np.int64(147): array(0.66666667),\n",
       "  np.int64(154): array(0.66666667),\n",
       "  np.int64(161): array(0.66666667),\n",
       "  np.int64(168): array(0.5),\n",
       "  np.int64(175): array(0.5),\n",
       "  np.int64(182): array(0.5),\n",
       "  np.int64(189): array(0.5)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('附件_分组_XY.xlsx')\n",
    "df['week'] = df['检测孕周_天数'] \n",
    "\n",
    "# 确认week的范围\n",
    "print(max(df['week']))\n",
    "print(min(df['week']))\n",
    "\n",
    "# 计算每个组别的P_false曲线\n",
    "P_false_curves = {}\n",
    "for group in df['组别'].unique():\n",
    "    P_false_curves[group] = P_false(df, group)\n",
    "\n",
    "P_false_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc24dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_optimal_results(P_false_curves, weight_combinations):\n",
    "    \"\"\"\n",
    "    计算所有权重组合在各个组的最小risk和最佳检测时间\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for w1, w2 in weight_combinations:\n",
    "        _, optimal_times = risk(P_false_curves, w1, w2)\n",
    "        \n",
    "        for group, (best_t, min_risk) in optimal_times.items():\n",
    "            results.append({\n",
    "                '权重组合': f'w1={w1}, w2={w2}',\n",
    "                '组别': group,\n",
    "                '最佳检测时间(天)': best_t,\n",
    "                '最小风险值': min_risk,\n",
    "                'w1': w1,\n",
    "                'w2': w2\n",
    "            })\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b18759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             权重组合  组别  最佳检测时间(天)     最小风险值   w1   w2\n",
      "0  w1=0.8, w2=0.2   2         77  0.080000  0.8  0.2\n",
      "1  w1=0.8, w2=0.2   3         70  0.080000  0.8  0.2\n",
      "2  w1=0.8, w2=0.2   4         84  0.200000  0.8  0.2\n",
      "3  w1=0.8, w2=0.2   5        175  0.470192  0.8  0.2\n",
      "4  w1=0.8, w2=0.2   1        119  0.462500  0.8  0.2\n",
      "5  w1=0.7, w2=0.3   2         77  0.070000  0.7  0.3\n",
      "6  w1=0.7, w2=0.3   3         70  0.070000  0.7  0.3\n",
      "7  w1=0.7, w2=0.3   4         84  0.175000  0.7  0.3\n",
      "8  w1=0.7, w2=0.3   5        175  0.512981  0.7  0.3\n",
      "9  w1=0.7, w2=0.3   1        119  0.443750  0.7  0.3\n"
     ]
    }
   ],
   "source": [
    "weight_combinations = [\n",
    "    (0.8, 0.2),  \n",
    "    (0.7, 0.3),  \n",
    "    (0.6, 0.4),  \n",
    "    (0.5, 0.5),  \n",
    "    (0.9, 0.1),  \n",
    "    (0.4, 0.6)   \n",
    "]\n",
    "\n",
    "results_df = calculate_all_optimal_results(P_false_curves, weight_combinations)\n",
    "\n",
    "excel_filename = '最优检测时间结果_use_1.xlsx'\n",
    "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='完整结果', index=False)\n",
    "    \n",
    "    for weight_combo in results_df['权重组合'].unique():\n",
    "        combo_df = results_df[results_df['权重组合'] == weight_combo]\n",
    "        sheet_name = f\"权重{weight_combo.replace('w1=', '').replace('w2=', '').replace(', ', '_')}\"\n",
    "        combo_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    summary_df = results_df.pivot_table(\n",
    "        index='组别', \n",
    "        columns='权重组合', \n",
    "        values=['最佳检测时间(天)', '最小风险值'],\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    summary_df.to_excel(writer, sheet_name='汇总表')\n",
    "\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad907417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   组别  孕周t(天)  P_false  P_late\n",
      "0   1      10      NaN       0\n",
      "1   1      11      NaN       0\n",
      "2   1      12      NaN       0\n",
      "3   1      13      NaN       0\n",
      "4   1      14      NaN       0\n",
      "5   1      15      NaN       0\n",
      "6   1      16      NaN       0\n",
      "7   1      17      NaN       0\n",
      "8   1      18      NaN       0\n",
      "9   1      19      NaN       0\n",
      "组别 1: 平均P_false = nan, 最大值 = nan, 最小值 = nan\n",
      "组别 2: 平均P_false = nan, 最大值 = nan, 最小值 = nan\n",
      "组别 3: 平均P_false = nan, 最大值 = nan, 最小值 = nan\n",
      "组别 4: 平均P_false = nan, 最大值 = nan, 最小值 = nan\n",
      "组别 5: 平均P_false = nan, 最大值 = nan, 最小值 = nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def pfalse_plate(df, P_false_curves):\n",
    "    groups = sorted(df['组别'].unique())\n",
    "    t_values = np.arange(10, 28)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for group in groups:\n",
    "        for t in t_values:\n",
    "            # 计算P_false\n",
    "            p_false = P_false_curves.get(group, {}).get(t, np.nan)\n",
    "            \n",
    "            # 计算P_late\n",
    "            p_late = P_late(t)\n",
    "            \n",
    "            results.append({\n",
    "                '组别': group,\n",
    "                '孕周t(天)': t,\n",
    "                'P_false': p_false,\n",
    "                'P_late': p_late\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "all_results_df = pfalse_plate(df, P_false_curves)\n",
    "\n",
    "excel_filename = '各组别_P_false_P_late_详细数据_use_1.xlsx'\n",
    "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "    all_results_df.to_excel(writer, sheet_name='完整数据', index=False)\n",
    "\n",
    "    for group in all_results_df['组别'].unique():\n",
    "        group_df = all_results_df[all_results_df['组别'] == group]\n",
    "        sheet_name = f'组别{group}'\n",
    "        group_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    pivot_false = all_results_df.pivot_table(\n",
    "        index='孕周t(天)', \n",
    "        columns='组别', \n",
    "        values='P_false',\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    pivot_late = all_results_df.pivot_table(\n",
    "        index='孕周t(天)', \n",
    "        columns='组别', \n",
    "        values='P_late',\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    \n",
    "    pivot_false.to_excel(writer, sheet_name='P_false_汇总')\n",
    "    pivot_late.to_excel(writer, sheet_name='P_late_汇总')\n",
    "\n",
    "print(all_results_df.head(10))\n",
    "\n",
    "for group in all_results_df['组别'].unique():\n",
    "    group_data = all_results_df[all_results_df['组别'] == group]\n",
    "    avg_p_false = group_data['P_false'].mean()\n",
    "    max_p_false = group_data['P_false'].max()\n",
    "    min_p_false = group_data['P_false'].min()\n",
    "    print(f\"组别 {group}: 平均P_false = {avg_p_false:.4f}, 最大值 = {max_p_false:.4f}, 最小值 = {min_p_false:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c44ca9",
   "metadata": {},
   "source": [
    "## 使用熵权法所得的权重进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d52488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各组最优检测时间和最小风险:\n",
      "==================================================\n",
      "2: 最优检测时间 = 77天(11.0周), 最小风险 = 0.0632\n",
      "    权重: w1 = 0.6320, w2 = 0.3680\n",
      "--------------------------------------------------\n",
      "3: 最优检测时间 = 70天(10.0周), 最小风险 = 0.0808\n",
      "    权重: w1 = 0.8080, w2 = 0.1920\n",
      "--------------------------------------------------\n",
      "4: 最优检测时间 = 84天(12.0周), 最小风险 = 0.1384\n",
      "    权重: w1 = 0.5535, w2 = 0.4465\n",
      "--------------------------------------------------\n",
      "5: 最优检测时间 = 168天(24.0周), 最小风险 = 0.5385\n",
      "    权重: w1 = 0.6344, w2 = 0.3656\n",
      "--------------------------------------------------\n",
      "1: 最优检测时间 = 119天(17.0周), 最小风险 = 0.4010\n",
      "    权重: w1 = 0.4721, w2 = 0.5279\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def risk(P_false_curves, weights_list):\n",
    "    risk_results = {}\n",
    "    optimal_times = {}\n",
    "    \n",
    "    for i, (group, p_false_curve) in enumerate(P_false_curves.items()):\n",
    "        if i >= 5:  \n",
    "            break\n",
    "            \n",
    "        w1, w2 = weights_list[i]\n",
    "        group_risk = {}\n",
    "        \n",
    "        for t, p_false in p_false_curve.items():\n",
    "            risk_value = w1 * p_false + w2 * P_late(t)\n",
    "            group_risk[t] = risk_value\n",
    "    \n",
    "        min_risk_t = min(group_risk.items(), key=lambda x: x[1])[0]\n",
    "        min_risk_value = group_risk[min_risk_t]\n",
    "        \n",
    "        risk_results[group] = {\n",
    "            'risk_curve': group_risk,\n",
    "            'weights': (w1, w2),\n",
    "            'optimal_time': min_risk_t,\n",
    "            'min_risk': min_risk_value\n",
    "        }\n",
    "        optimal_times[group] = (min_risk_t, min_risk_value)\n",
    "    \n",
    "    return risk_results, optimal_times\n",
    "\n",
    "weights_list = [\n",
    "    (0.6320, 0.3680),  \n",
    "    (0.8080, 0.1920),  \n",
    "    (0.5535, 0.4465),  \n",
    "    (0.6344, 0.3656),  \n",
    "    (0.4721, 0.5279)   \n",
    "]\n",
    "\n",
    "risk_results, optimal_times = risk(P_false_curves, weights_list)\n",
    "\n",
    "print(\"各组最优检测时间和最小风险:\")\n",
    "print(\"=\" * 50)\n",
    "for group, (optimal_time, min_risk) in optimal_times.items():\n",
    "    w1, w2 = risk_results[group]['weights']\n",
    "    print(f\"{group}: 最优检测时间 = {optimal_time}天({optimal_time/7}周), 最小风险 = {min_risk:.4f}\")\n",
    "    print(f\"    权重: w1 = {w1:.4f}, w2 = {w2:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUMCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
